{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time embedding\n",
    "\n",
    "### Parameters\n",
    "- `input_dim` is the number of time components. For example, the date 10.02.1993 has 3 components: year, month and year respectively\n",
    "- `embed_dim_target` is the hidden dimension of the embedding\n",
    "- `seq_len` is the length of the input sequence\n",
    "- `BATCH_SIZE` is the size of the minibach\n",
    "\n",
    "Embedding mapping; input (BATCH_SIZE, seq_len, **input_dim**) -> output (BATCH_SIZE, seq_len, **embed_dim**$\\times$**input_dim**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([1, 5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4980, 0.2627, 0.5106],\n",
       "         [0.1706, 0.3551, 0.4692],\n",
       "         [0.9027, 0.5891, 0.4011],\n",
       "         [0.7878, 0.1128, 0.7704],\n",
       "         [0.6210, 0.8645, 0.9596]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 3\n",
    "embed_dim_target = 12\n",
    "seq_len = 5\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "x = torch.rand(BATCH_SIZE,seq_len,input_dim)\n",
    "print(f\"X shape: {x.shape}\")\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Latent space subdivision\n",
    "In order to have the specified `embed_dim_target`, we need to spread it onto the time components (`input_dim`) before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert embed_dim_target % input_dim == 0\n",
    "embed_dim = embed_dim_target // input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_function = torch.sin\n",
    "embed_weight = torch.rand(input_dim,embed_dim)\n",
    "embed_bias = torch.rand(input_dim,embed_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Expand the time components on diagonal matrices\n",
    "\n",
    "If we have 3 time components for each point in the sequence, they will be placed on the diagonal of a 3x3 square matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape after diag_embed: torch.Size([1, 5, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[5.5029e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 5.5779e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 7.4214e-04]],\n",
       "\n",
       "         [[7.7242e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 1.7727e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 1.5817e-01]],\n",
       "\n",
       "         [[3.2493e-02, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 9.2086e-01, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 2.0280e-02]],\n",
       "\n",
       "         [[8.9422e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 1.0928e-02, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 5.8273e-02]],\n",
       "\n",
       "         [[4.9967e-01, 0.0000e+00, 0.0000e+00],\n",
       "          [0.0000e+00, 8.7002e-02, 0.0000e+00],\n",
       "          [0.0000e+00, 0.0000e+00, 9.2712e-01]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_diag = torch.diag_embed(x)\n",
    "print(f\"X shape after diag_embed: {x_diag.shape}\")\n",
    "x_diag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Multiply the square diagonal matrices with the weights and add the bias\n",
    "This step changes the dimension of the temporal components `input_dim` (3) --> `embed_dim` (12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moltiplication with the weights of shape: torch.Size([3, 4])\n",
      "X shape after matmul: torch.Size([1, 5, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.1625, 0.7545, 0.8021, 0.9528],\n",
       "          [0.7828, 0.2907, 0.7901, 1.1776],\n",
       "          [0.1552, 0.0167, 0.4054, 0.9135]],\n",
       "\n",
       "         [[1.2985, 0.8171, 0.9025, 0.9880],\n",
       "          [0.7305, 0.1645, 0.5024, 0.9820],\n",
       "          [0.2756, 0.1611, 0.4209, 0.9656]],\n",
       "\n",
       "         [[0.8454, 0.6087, 0.5682, 0.8708],\n",
       "          [0.8327, 0.4111, 1.0647, 1.3643],\n",
       "          [0.1701, 0.0346, 0.4073, 0.9199]],\n",
       "\n",
       "         [[1.3730, 0.8514, 0.9575, 1.0073],\n",
       "          [0.7077, 0.1093, 0.3766, 0.8965],\n",
       "          [0.1992, 0.0695, 0.4110, 0.9325]],\n",
       "\n",
       "         [[1.1315, 0.7403, 0.7793, 0.9448],\n",
       "          [0.7181, 0.1345, 0.4341, 0.9356],\n",
       "          [0.8637, 0.8665, 0.4966, 1.2204]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x.shape = (bs, sequence_length, input_dim, input_dim)\n",
    "x_affine = torch.matmul(x_diag, embed_weight) + embed_bias\n",
    "print(f\"Moltiplication with the weights of shape: {embed_weight.shape}\")\n",
    "print(f\"X shape after matmul: {x_affine.shape}\")\n",
    "x_affine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. On the last dimension, we split between the zero component and the higher order ones, and apply the activation function to the latter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero component shape: torch.Size([1, 5, 3, 1])\n",
      "Higher order components shape: torch.Size([1, 5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x_affine_0, x_affine_remain = torch.split(x_affine, [1, embed_dim - 1], dim=-1)\n",
    "x_affine_remain = act_function(x_affine_remain)\n",
    "print(f\"Zero component shape: {x_affine_0.shape}\")\n",
    "print(f\"Higher order components shape: {x_affine_remain.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Recompose the zero and higher order components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([1, 5, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x_join = torch.cat([x_affine_0, x_affine_remain], dim=-1)\n",
    "print(f\"X shape: {x_join.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Reshape the last component to flatten the [``input_dim``, ``embed_dim``] matrix into a [``input_dim``$\\times$``embed_dim``]\n",
    "Note that ``input_dim``$\\times$``embed_dim`` = ``embed_dim_target``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([1, 5, 12])\n"
     ]
    }
   ],
   "source": [
    "x_output = x_join.view(x_join.size(0), x_join.size(1), -1)\n",
    "print(f\"X shape: {x_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how this view operation looks like, take a look at the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [2., 2., 2.],\n",
       "        [3., 3., 3.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([[1,1,1],[2,2,2],[3,3,3]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 2., 2., 2., 3., 3., 3.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.view(1,a.size(0)*a.size(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prochain_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, log\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import numpy as np\n",
    "import sys\n",
    "ROOT_DIR = \"../\"\n",
    "sys.path.append(ROOT_DIR)\n",
    "from prochain_transformer.modules.extra_layers import UniformAttentionMask\n",
    "\n",
    "mask = [False,False,False,False]\n",
    "mask_layer = UniformAttentionMask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.1199, -0.0072, -0.1170,  0.0055],\n",
      "          [-0.0676, -0.0626, -0.1043, -0.0312],\n",
      "          [-0.0723,  0.0187, -0.0694,  0.0611],\n",
      "          [-0.1176, -0.1026, -0.1503, -0.0732]]]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "seq_len = 4          # sequence length (here we assume the same for input/output, but it can be different)\n",
    "heads = 1            # number of heads (multi-head attention)\n",
    "d_model = 12         # Embedding dimension (?)\n",
    "d_query_key = 9      # Dimension for the query and key vectors\n",
    "\n",
    "# x = torch.ones(BATCH_SIZE,seq_len,d_model) # d_model \n",
    "x = torch.rand(BATCH_SIZE,seq_len,d_model) # d_model \n",
    "multi_projection = nn.Linear(d_model, d_query_key * heads, bias=False)\n",
    "\n",
    "\n",
    "query_projection = nn.Linear(d_model, d_query_key * heads)\n",
    "key_projection = nn.Linear(d_model, d_query_key * heads)\n",
    "\n",
    "query = query_projection(x)\n",
    "key = key_projection(x)\n",
    "\n",
    "query_view = query.view((BATCH_SIZE, seq_len, heads, -1))\n",
    "key_view = key.view((BATCH_SIZE, seq_len, heads, -1))\n",
    "\n",
    "scale = 1.0 / sqrt(d_query_key)\n",
    "\n",
    "scores = scale *torch.einsum(\"blhe,bshe->bhls\", query_view, key_view)\n",
    "scores_mask = mask_layer(scores,mask)\n",
    "print(scores_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2350, 0.2630, 0.2356, 0.2664],\n",
      "          [0.2496, 0.2509, 0.2406, 0.2589],\n",
      "          [0.2358, 0.2583, 0.2365, 0.2694],\n",
      "          [0.2482, 0.2520, 0.2402, 0.2595]]]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[[0.2350, 0.2630, 0.2356, 0.2664],\n",
      "          [0.2496, 0.2509, 0.2406, 0.2589],\n",
      "          [0.2358, 0.2583, 0.2365, 0.2694],\n",
      "          [0.2482, 0.2520, 0.2402, 0.2595]]]], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[[[-0.7423,  0.5358,  0.2884, -0.1044, -0.4614, -0.0761,  0.2985,\n",
      "            0.5252,  0.1182,  0.3812, -0.0836, -0.6239]],\n",
      "\n",
      "         [[-0.7415,  0.5299,  0.2883, -0.1036, -0.4668, -0.0745,  0.3012,\n",
      "            0.5246,  0.1197,  0.3803, -0.0820, -0.6250]],\n",
      "\n",
      "         [[-0.7428,  0.5359,  0.2884, -0.1037, -0.4619, -0.0754,  0.2995,\n",
      "            0.5250,  0.1186,  0.3811, -0.0827, -0.6244]],\n",
      "\n",
      "         [[-0.7416,  0.5304,  0.2883, -0.1037, -0.4663, -0.0746,  0.3010,\n",
      "            0.5247,  0.1195,  0.3804, -0.0821, -0.6249]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.7423,  0.5358,  0.2884, -0.1044, -0.4614, -0.0761,  0.2985,\n",
      "            0.5252,  0.1182,  0.3812, -0.0836, -0.6239]],\n",
      "\n",
      "         [[-0.7415,  0.5299,  0.2883, -0.1036, -0.4668, -0.0745,  0.3012,\n",
      "            0.5246,  0.1197,  0.3803, -0.0820, -0.6250]],\n",
      "\n",
      "         [[-0.7428,  0.5359,  0.2884, -0.1037, -0.4619, -0.0754,  0.2995,\n",
      "            0.5250,  0.1186,  0.3811, -0.0827, -0.6244]],\n",
      "\n",
      "         [[-0.7416,  0.5304,  0.2883, -0.1037, -0.4663, -0.0746,  0.3010,\n",
      "            0.5247,  0.1195,  0.3804, -0.0821, -0.6249]]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "A_mask = torch.softmax(scores_mask, dim=-1)\n",
    "A = torch.softmax(scores, dim=-1)\n",
    "\n",
    "value_projection = nn.Linear(d_model, d_model *heads)\n",
    "values = value_projection(x)\n",
    "values_view = values.view(BATCH_SIZE, seq_len, heads, -1)\n",
    "\n",
    "V_mask = torch.einsum(\"bhls,bshd->blhd\", A_mask, values_view)\n",
    "V = torch.einsum(\"bhls,bshd->blhd\", A, values_view)\n",
    "\n",
    "print(A_mask)\n",
    "print(A)\n",
    "print(V_mask)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 1, 12])\n",
      "torch.Size([1, 4, 1, 12])\n",
      "tensor([[[[-0.0204,  0.2157,  0.1236,  0.5567,  0.9937, -0.0930, -0.7458,\n",
      "           -0.3583, -0.3070, -0.1132, -0.1033, -0.2142]],\n",
      "\n",
      "         [[-0.0183,  0.2218,  0.1233,  0.5560,  0.9940, -0.0936, -0.7424,\n",
      "           -0.3679, -0.3067, -0.1060, -0.1059, -0.2192]],\n",
      "\n",
      "         [[-0.0209,  0.2170,  0.1230,  0.5571,  0.9942, -0.0927, -0.7453,\n",
      "           -0.3590, -0.3070, -0.1134, -0.1032, -0.2154]],\n",
      "\n",
      "         [[-0.0185,  0.2212,  0.1233,  0.5561,  0.9940, -0.0935, -0.7427,\n",
      "           -0.3670, -0.3067, -0.1067, -0.1057, -0.2188]]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[[-0.0204,  0.2157,  0.1236,  0.5567,  0.9937, -0.0930, -0.7458,\n",
      "           -0.3583, -0.3070, -0.1132, -0.1033, -0.2142]],\n",
      "\n",
      "         [[-0.0183,  0.2218,  0.1233,  0.5560,  0.9940, -0.0936, -0.7424,\n",
      "           -0.3679, -0.3067, -0.1060, -0.1059, -0.2192]],\n",
      "\n",
      "         [[-0.0209,  0.2170,  0.1230,  0.5571,  0.9942, -0.0927, -0.7453,\n",
      "           -0.3590, -0.3070, -0.1134, -0.1032, -0.2154]],\n",
      "\n",
      "         [[-0.0185,  0.2212,  0.1233,  0.5561,  0.9940, -0.0935, -0.7427,\n",
      "           -0.3670, -0.3067, -0.1067, -0.1057, -0.2188]]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "value_projection = nn.Linear(d_model, d_model *heads)\n",
    "values = value_projection(x)\n",
    "values_view = values.view(BATCH_SIZE, seq_len, heads, -1)\n",
    "\n",
    "V_mask = torch.einsum(\"bhls,bshd->blhd\", A, values_view)\n",
    "V = torch.einsum(\"bhls,bshd->blhd\", A, values_view)\n",
    "\n",
    "print(V_mask.shape)\n",
    "print(V.shape)\n",
    "print(V_mask)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_projection = nn.Linear(d_model*heads, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 12])\n"
     ]
    }
   ],
   "source": [
    "V_mask = V_mask.reshape(BATCH_SIZE,seq_len,-1)\n",
    "V = V.reshape(BATCH_SIZE,seq_len,-1)\n",
    "print(V_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_projection = nn.Linear(d_model*heads, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 12])\n",
      "tensor([[[False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False],\n",
      "         [False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False],\n",
      "         [False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False],\n",
      "         [False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False]]])\n",
      "tensor([[[-0.3159,  0.2257, -0.0707, -0.3978,  0.1626, -0.2249,  0.3202,\n",
      "           0.4620, -0.0756,  0.2144,  0.1905,  0.1502],\n",
      "         [-0.3179,  0.2219, -0.0688, -0.3994,  0.1629, -0.2202,  0.3192,\n",
      "           0.4622, -0.0770,  0.2129,  0.1924,  0.1496],\n",
      "         [-0.3156,  0.2252, -0.0706, -0.3984,  0.1632, -0.2249,  0.3198,\n",
      "           0.4625, -0.0756,  0.2140,  0.1904,  0.1502],\n",
      "         [-0.3177,  0.2223, -0.0690, -0.3993,  0.1629, -0.2207,  0.3193,\n",
      "           0.4622, -0.0769,  0.2130,  0.1922,  0.1497]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.3159,  0.2257, -0.0707, -0.3978,  0.1626, -0.2249,  0.3202,\n",
      "           0.4620, -0.0756,  0.2144,  0.1905,  0.1502],\n",
      "         [-0.3179,  0.2219, -0.0688, -0.3994,  0.1629, -0.2202,  0.3192,\n",
      "           0.4622, -0.0770,  0.2129,  0.1924,  0.1496],\n",
      "         [-0.3156,  0.2252, -0.0706, -0.3984,  0.1632, -0.2249,  0.3198,\n",
      "           0.4625, -0.0756,  0.2140,  0.1904,  0.1502],\n",
      "         [-0.3177,  0.2223, -0.0690, -0.3993,  0.1629, -0.2207,  0.3193,\n",
      "           0.4622, -0.0769,  0.2130,  0.1922,  0.1497]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = out_projection(V)\n",
    "out_mask = out_projection(V_mask)\n",
    "print(out_mask.shape)\n",
    "print(abs(out)>abs(out_mask))\n",
    "print(out)\n",
    "print(out_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prochain_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
